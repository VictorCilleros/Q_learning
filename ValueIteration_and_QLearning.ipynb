{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rlberry-py/tutorials/blob/main/Value%20Iteration%20and%20Q-Learning/Value_Iteration_and_Q_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io_4iovMTlzT"
   },
   "source": [
    "# Tutorial - Value Iteration and Q-Learning\n",
    "---------------------------------\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "* Implement the value iteration algorithm to approximate the value function when *a model of the environment is available*.\n",
    "* Implement the Q-Learning algorithm to approximate the value function when *the model is unknown*, that is, the agent must learn through interactions.\n",
    "\n",
    "We start with a short review of these algorithms.\n",
    "\n",
    "\n",
    "## Markov decision processes and value functions\n",
    "\n",
    "In reinforcement learning, an agent interacts with an enviroment by taking actions and observing rewards. Its goal is to learn a *policy*, that is, a mapping from states to actions, that maximizes the amount of reward it gathers.\n",
    "\n",
    "The enviroment is modeled as a __Markov decision process (MDP)__, defined by a set of states $\\mathcal{S}$, a set of actions $\\mathcal{A}$, a reward function $r(s, a)$ and transition probabilities $P(s'|s,a)$. When an agent takes action $a$ in state $s$, it receives a random reward with mean $r(s,a)$ and makes a transion to a state $s'$ distributed according to $P(s'|s,a)$.\n",
    "\n",
    "A __policy__ $\\pi$ is such that $\\pi(a|s)$ gives the probability of choosing an action $a$ in state $s$. __If the policy is deterministic__, we denote by $\\pi(s)$ the action that it chooses in state $s$. We are interested in finding a policy that maximizes the value function $V^\\pi$, defined as \n",
    "\n",
    "$$\n",
    "V^\\pi(s) = \\sum_{a\\in \\mathcal{A}} \\pi(a|s) Q^\\pi(s, a), \n",
    "\\quad \\text{where} \\quad \n",
    "Q^\\pi(s, a) = \\mathbf{E}\\left[ \\sum_{t=0}^\\infty \\gamma^t r(S_t, A_t)  \\Big| S_0 = s, A_0 = a\\right].\n",
    "$$\n",
    "and represents the mean of the sum of discounted rewards gathered by the policy $\\pi$ in the MDP, where $\\gamma \\in [0, 1[$ is a discount factor ensuring the convergence of the sum. \n",
    "\n",
    "The __action-value function__ $Q^\\pi$ is the __fixed point of the Bellman operator $T^\\pi$__:\n",
    "\n",
    "$$ \n",
    "Q^\\pi(s, a) = T^\\pi Q^\\pi(s, a)\n",
    "$$\n",
    "where, for any function $f: \\mathcal{S}\\times\\mathcal{A} \\to \\mathbb{R}$\n",
    "$$\n",
    "T^\\pi f(s, a) =  r(s, a) + \\gamma \\sum_{s'} P(s'|s,a) \\left(\\sum_{a'}\\pi(a'|s')f(s',a')\\right) \n",
    "$$\n",
    "\n",
    "\n",
    "The __optimal value function__, defined as $V^*(s) = \\max_\\pi V^\\pi(s)$ can be shown to satisfy $V^*(s) = \\max_a Q^*(s, a)$, where $Q^*$ is the __fixed point of the optimal Bellman operator $T^*$__: \n",
    "\n",
    "$$ \n",
    "Q^*(s, a) = T^* Q^*(s, a)\n",
    "$$\n",
    "where, for any function $f: \\mathcal{S}\\times\\mathcal{A} \\to \\mathbb{R}$\n",
    "$$\n",
    "T^* f(s, a) =  r(s, a) + \\gamma \\sum_{s'} P(s'|s,a) \\max_{a'} f(s', a')\n",
    "$$\n",
    "and there exists an __optimal policy__ which is deterministic, given by $\\pi^*(s) \\in \\arg\\max_a Q^*(s, a)$.\n",
    "\n",
    "\n",
    "## Value iteration\n",
    "\n",
    "If both the reward function $r$ and the transition probablities $P$ are known, we can compute $Q^*$ using value iteration, which proceeds as follows:\n",
    "\n",
    "1. Start with arbitrary $Q_0$, set $t=0$.\n",
    "2. Compute $Q_{t+1}(s, a) = T^*Q_t(s,a)$ for every $(s, a)$.\n",
    "3. If $\\max_{s,a} | Q_{t+1}(s, a) -  Q_t(s,a)| \\leq \\varepsilon$, return $Q_{t}$. Otherwise, set $t \\gets t+1$ and go back to 2. \n",
    "\n",
    "The convergence is guaranteed by the contraction property of the Bellman operator, and $Q_{t+1}$ can be shown to be a good approximation of $Q^*$ for small epsilon. \n",
    "\n",
    "__Question__: Can you bound the error $\\max_{s,a} | Q^*(s, a) -  Q_t(s,a)|$ as a function of $\\gamma$ and $\\varepsilon$?\n",
    "\n",
    "## Q-Learning\n",
    "\n",
    "In value iteration, we need to know $r$ and $P$ to implement the Bellman operator. When these quantities are not available, we can approximate $Q^*$ using *samples* from the environment with the Q-Learning algorithm.\n",
    "\n",
    "Q-Learning with __$\\varepsilon$-greedy exploration__ proceeds as follows:\n",
    "\n",
    "1. Start with arbitrary $Q_0$, get starting state $s_0$, set $t=0$.\n",
    "2. Choosing action $a_t$: \n",
    "  * With probability $\\varepsilon$ choose $a_t$ randomly (uniform distribution)  \n",
    "  * With probability $1-\\varepsilon$, choose $a_t \\in \\arg\\max_a Q_t(s_t, a)$.\n",
    "3. Take action $a_t$, observe next state $s_{t+1}$ and reward $r_t$.\n",
    "4. Compute error $\\delta_t = r_t + \\gamma \\max_a Q_t(s_{t+1}, a) - Q_t(s_t, a_t)$.\n",
    "5. Update \n",
    "  * $Q_{t+1}(s, a) = Q_t(s, a) + \\alpha_t(s,a) \\delta_t$,  __if $s=s_t$ and $a=a_t$__\n",
    "  * $Q_{t+1}(s, a) = Q_{t}(s, a)$ otherwise.\n",
    "\n",
    "Here, $\\alpha_t(s,a)$ is a learning rate that can depend, for instance, on the number of times the algorithm has visited the state-action pair $(s, a)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYq9-63OR8RW"
   },
   "source": [
    "# Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AxepTGrNR3DX",
    "outputId": "42376421-d387-42a8-a943-0d1c5b5b3db0"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  print(\"Installing packages, please wait a few moments. Restart the runtime after the installation.\")\n",
    "\n",
    "  # install rlberry library\n",
    "  !pip install git+https://github.com/rlberry-py/rlberry.git@v0.3.0#egg=rlberry[default] > /dev/null 2>&1\n",
    "\n",
    "  # packages required to show video\n",
    "  !pip install pyvirtualdisplay > /dev/null 2>&1\n",
    "  !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_bPhqKlSiF0",
    "outputId": "959689cb-1e62-41f3-c1ac-71741bd5bb48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f799eb86a50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create directory for saving videos\n",
    "!mkdir videos > /dev/null 2>&1\n",
    "\n",
    "# The following code is will be used to visualize the environments.\n",
    "import base64\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython import display as ipythondisplay\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "def show_video(filename=None, directory='./videos'):\n",
    "    \"\"\"\n",
    "    Either show all videos in a directory (if filename is None) or \n",
    "    show video corresponding to filename.\n",
    "    \"\"\"\n",
    "    html = []\n",
    "    if filename is not None:\n",
    "        files = Path('./').glob(filename)\n",
    "    else:\n",
    "        files = Path(directory).glob(\"*.mp4\")\n",
    "    for mp4 in files:\n",
    "        print(mp4)\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append('''<video alt=\"{}\" autoplay \n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
    "     \n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(800, 800))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ZYZCXMpisE_O"
   },
   "outputs": [],
   "source": [
    "# other required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterlab\n",
      "  Downloading jupyterlab-3.5.0-py3-none-any.whl (8.8 MB)\n",
      "     ---------------------------------------- 8.8/8.8 MB 46.9 MB/s eta 0:00:00\n",
      "Collecting jupyter-server<3,>=1.16.0\n",
      "  Downloading jupyter_server-1.23.3-py3-none-any.whl (346 kB)\n",
      "     ------------------------------------- 346.4/346.4 kB 22.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyterlab) (21.3)\n",
      "Collecting jupyterlab-server~=2.10\n",
      "  Downloading jupyterlab_server-2.16.3-py3-none-any.whl (54 kB)\n",
      "     ---------------------------------------- 54.1/54.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: ipython in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyterlab) (8.7.0)\n",
      "Requirement already satisfied: tornado>=6.1.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyterlab) (6.2)\n",
      "Collecting nbclassic\n",
      "  Downloading nbclassic-0.4.8-py3-none-any.whl (9.8 MB)\n",
      "     ---------------------------------------- 9.8/9.8 MB 36.9 MB/s eta 0:00:00\n",
      "Collecting jinja2>=2.1\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.1/133.1 kB 7.7 MB/s eta 0:00:00\n",
      "Collecting tomli\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyterlab) (5.1.0)\n",
      "Collecting notebook<7\n",
      "  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n",
      "     ------------------------------------- 439.1/439.1 kB 28.6 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Downloading terminado-0.17.0-py3-none-any.whl (16 kB)\n",
      "Collecting websocket-client\n",
      "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.3/55.3 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (23.2.0)\n",
      "Collecting anyio<4,>=3.1.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "     ---------------------------------------- 80.6/80.6 kB ? eta 0:00:00\n",
      "Collecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting nbconvert>=6.4.4\n",
      "  Downloading nbconvert-7.2.5-py3-none-any.whl (273 kB)\n",
      "     ------------------------------------- 273.3/273.3 kB 17.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (7.4.7)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-server<3,>=1.16.0->jupyterlab) (5.6.0)\n",
      "Collecting pywinpty\n",
      "  Downloading pywinpty-2.0.9-cp38-none-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 45.1 MB/s eta 0:00:00\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.15.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.1/60.1 kB ? eta 0:00:00\n",
      "Collecting nbformat>=5.2.0\n",
      "  Downloading nbformat-5.7.0-py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting Send2Trash\n",
      "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-core->jupyterlab) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-core->jupyterlab) (227)\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Collecting jsonschema>=3.0.1\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.4/90.4 kB ? eta 0:00:00\n",
      "Collecting babel\n",
      "  Downloading Babel-2.11.0-py3-none-any.whl (9.5 MB)\n",
      "     ---------------------------------------- 9.5/9.5 MB 22.5 MB/s eta 0:00:00\n",
      "Collecting json5\n",
      "  Downloading json5-0.9.10-py2.py3-none-any.whl (19 kB)\n",
      "Collecting importlib-metadata>=4.8.3\n",
      "  Downloading importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from notebook<7->jupyterlab) (1.5.6)\n",
      "Collecting ipython-genutils\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from notebook<7->jupyterlab) (6.17.1)\n",
      "Collecting notebook-shim>=0.1.0\n",
      "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (3.0.33)\n",
      "Requirement already satisfied: stack-data in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (0.6.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (0.18.2)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (2.13.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipython->jupyterlab) (0.1.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from packaging->jupyterlab) (3.0.9)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting idna>=2.8\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.5/61.5 kB ? eta 0:00:00\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jedi>=0.16->ipython->jupyterlab) (0.8.3)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.8/58.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.19.2-cp38-cp38-win_amd64.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-client>=6.1.12->jupyter-server<3,>=1.16.0->jupyterlab) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from jupyter-client>=6.1.12->jupyter-server<3,>=1.16.0->jupyterlab) (0.4)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 72.0/72.0 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "     -------------------------------------- 128.2/128.2 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting mistune<3,>=2.0.3\n",
      "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
      "     -------------------------------------- 160.9/160.9 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython->jupyterlab) (0.2.5)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Collecting pytz>=2015.7\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "     -------------------------------------- 498.1/498.1 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: debugpy>=1.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipykernel->notebook<7->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ipykernel->notebook<7->jupyterlab) (5.9.0)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.6/140.6 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (2022.9.24)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from stack-data->ipython->jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from stack-data->ipython->jupyterlab) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from stack-data->ipython->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython->jupyterlab) (1.16.0)\n",
      "Collecting cffi>=1.0.1\n",
      "  Downloading cffi-1.15.1-cp38-cp38-win_amd64.whl (178 kB)\n",
      "     -------------------------------------- 178.8/178.8 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Collecting webencodings\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     -------------------------------------- 118.7/118.7 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: webencodings, Send2Trash, pytz, mistune, json5, ipython-genutils, fastjsonschema, zipp, websocket-client, urllib3, tomli, tinycss2, soupsieve, sniffio, pywinpty, pyrsistent, pycparser, prometheus-client, pkgutil-resolve-name, pandocfilters, MarkupSafe, jupyterlab-pygments, idna, defusedxml, charset-normalizer, bleach, babel, attrs, terminado, requests, jinja2, importlib-resources, importlib-metadata, cffi, beautifulsoup4, anyio, jsonschema, argon2-cffi-bindings, nbformat, argon2-cffi, nbclient, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, nbclassic, notebook, jupyterlab\n",
      "Successfully installed MarkupSafe-2.1.1 Send2Trash-1.8.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 attrs-22.1.0 babel-2.11.0 beautifulsoup4-4.11.1 bleach-5.0.1 cffi-1.15.1 charset-normalizer-2.1.1 defusedxml-0.7.1 fastjsonschema-2.16.2 idna-3.4 importlib-metadata-5.1.0 importlib-resources-5.10.0 ipython-genutils-0.2.0 jinja2-3.1.2 json5-0.9.10 jsonschema-4.17.3 jupyter-server-1.23.3 jupyterlab-3.5.0 jupyterlab-pygments-0.2.2 jupyterlab-server-2.16.3 mistune-2.0.4 nbclassic-0.4.8 nbclient-0.7.2 nbconvert-7.2.5 nbformat-5.7.0 notebook-6.5.2 notebook-shim-0.2.2 pandocfilters-1.5.0 pkgutil-resolve-name-1.3.10 prometheus-client-0.15.0 pycparser-2.21 pyrsistent-0.19.2 pytz-2022.6 pywinpty-2.0.9 requests-2.28.1 sniffio-1.3.0 soupsieve-2.3.2.post1 terminado-0.17.0 tinycss2-1.2.1 tomli-2.0.1 urllib3-1.26.13 webencodings-0.5.1 websocket-client-1.4.2 zipp-3.11.0\n",
      "Collecting rlberry[default]\n",
      "  Cloning https://github.com/rlberry-py/rlberry.git (to revision v0.3.0) to c:\\users\\utilisateur\\appdata\\local\\temp\\pip-install-sb05ec76\\rlberry_ed4fda72bd8546d29d647ba69db2f389\n",
      "  Resolved https://github.com/rlberry-py/rlberry.git to commit 8ea7532ea27fdc1c5ffb44293f9e350c924f7c65\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.2-cp38-cp38-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 43.7 MB/s eta 0:00:00\n",
      "Collecting gym\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from rlberry[default]) (1.23.4)\n",
      "Collecting docopt\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from rlberry[default]) (3.5.3)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "     ------------------------------------- 288.2/288.2 kB 17.4 MB/s eta 0:00:00\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "     ---------------------------------------- 155.4/155.4 kB ? eta 0:00:00\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.1.2-cp38-cp38-win_amd64.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 44.9 MB/s eta 0:00:00\n",
      "Collecting optuna\n",
      "  Using cached optuna-3.0.4-py3-none-any.whl (348 kB)\n",
      "Collecting pyvirtualdisplay\n",
      "  Using cached PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.56.4-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 38.8 MB/s eta 0:00:00\n",
      "Collecting PyOpenGL\n",
      "  Using cached PyOpenGL-3.1.6-py3-none-any.whl (2.4 MB)\n",
      "Collecting PyOpenGL-accelerate\n",
      "  Downloading PyOpenGL_accelerate-3.1.6-cp38-cp38-win_amd64.whl (351 kB)\n",
      "     ---------------------------------------- 351.2/351.2 kB ? eta 0:00:00\n",
      "Collecting ffmpeg-python\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "     ------------------------------------- 829.2/829.2 kB 51.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from gym->rlberry[default]) (5.1.0)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from matplotlib->rlberry[default]) (2.8.2)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp38-cp38-win_amd64.whl (23.2 MB)\n",
      "     --------------------------------------- 23.2/23.2 MB 27.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from numba->rlberry[default]) (65.5.0)\n",
      "Collecting sqlalchemy>=1.3.0\n",
      "  Downloading SQLAlchemy-1.4.44-cp38-cp38-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 33.3 MB/s eta 0:00:00\n",
      "Collecting alembic>=1.5.0\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Collecting scipy<1.9.0,>=1.7.0\n",
      "  Downloading scipy-1.8.1-cp38-cp38-win_amd64.whl (36.9 MB)\n",
      "     --------------------------------------- 36.9/36.9 MB 29.7 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.8.0\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.1.0-py3-none-any.whl (81 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from pandas->rlberry[default]) (2022.6)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from alembic>=1.5.0->optuna->rlberry[default]) (5.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from importlib-metadata>=4.8.0->gym->rlberry[default]) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->rlberry[default]) (1.16.0)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.1-cp38-cp38-win_amd64.whl (190 kB)\n",
      "     ------------------------------------- 190.7/190.7 kB 11.3 MB/s eta 0:00:00\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from colorlog->optuna->rlberry[default]) (0.4.6)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna->rlberry[default]) (22.1.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna->rlberry[default]) (0.2.5)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna->rlberry[default]) (2.1.1)\n",
      "Building wheels for collected packages: docopt, gym, rlberry, future, pyperclip\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7cc50503392d52e8d5c6b993b55cb14cf481cf6f87d0352963a5e76e5fe2e7d7\n",
      "  Stored in directory: c:\\users\\utilisateur\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827647 sha256=0172776278f4a2da1bb7d948332bf0f0a125346667d84b55af724e7c800855d1\n",
      "  Stored in directory: c:\\users\\utilisateur\\appdata\\local\\pip\\cache\\wheels\\17\\79\\65\\7afedc162d858b02708a3b8f7a6dd5b1000dcd5b0f894f7cc1\n",
      "  Building wheel for rlberry (pyproject.toml): started\n",
      "  Building wheel for rlberry (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rlberry: filename=rlberry-0.2.1.post217.dev0+168a660-py3-none-any.whl size=279781 sha256=4ebc8de5b402bc420c8f44a3e46fcf4c1fae904b27e05c9e820ea47b40a99633\n",
      "  Stored in directory: C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-njl8oewz\\wheels\\eb\\c3\\8b\\4a129769927ef65ecd37bdf238ff2b9d4656d9ff0a3e86c953\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=0ac9cee11a268d29686d8f691f6d370f24b37b2e667a1fe9279e74c4ac127d4d\n",
      "  Stored in directory: c:\\users\\utilisateur\\appdata\\local\\pip\\cache\\wheels\\8e\\70\\28\\3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11123 sha256=edc468f64e5a2ba08dc9b79063544935c267c96f319722bef004a55818d39e05\n",
      "  Stored in directory: c:\\users\\utilisateur\\appdata\\local\\pip\\cache\\wheels\\7f\\1a\\65\\84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built docopt gym rlberry future pyperclip\n",
      "Installing collected packages: pyvirtualdisplay, pyreadline3, pyperclip, PyOpenGL-accelerate, PyOpenGL, gym-notices, docopt, tqdm, scipy, pyyaml, pygame, PrettyTable, pbr, Mako, llvmlite, importlib-metadata, greenlet, future, dill, colorlog, cmd2, cmaes, cloudpickle, autopage, stevedore, sqlalchemy, pandas, numba, gym, ffmpeg-python, seaborn, cliff, alembic, rlberry, optuna\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.1.0\n",
      "    Uninstalling importlib-metadata-5.1.0:\n",
      "      Successfully uninstalled importlib-metadata-5.1.0\n",
      "Successfully installed Mako-1.2.4 PrettyTable-3.5.0 PyOpenGL-3.1.6 PyOpenGL-accelerate-3.1.6 alembic-1.8.1 autopage-0.5.1 cliff-4.1.0 cloudpickle-2.2.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 dill-0.3.6 docopt-0.6.2 ffmpeg-python-0.2.0 future-0.18.2 greenlet-2.0.1 gym-0.26.2 gym-notices-0.0.8 importlib-metadata-4.13.0 llvmlite-0.39.1 numba-0.56.4 optuna-3.0.4 pandas-1.5.2 pbr-5.11.0 pygame-2.1.2 pyperclip-1.8.2 pyreadline3-3.4.1 pyvirtualdisplay-3.0 pyyaml-6.0 rlberry-0.2.1.post217.dev0+168a660 scipy-1.8.1 seaborn-0.12.1 sqlalchemy-1.4.44 stevedore-4.1.1 tqdm-4.64.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rlberry-py/rlberry.git 'C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\pip-install-sb05ec76\\rlberry_ed4fda72bd8546d29d647ba69db2f389'\n",
      "  Running command git checkout -q 8ea7532ea27fdc1c5ffb44293f9e350c924f7c65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Install required libraries:\n",
    "!pip install jupyterlab\n",
    "!pip install git+https://github.com/rlberry-py/rlberry.git@v0.3.0#egg=rlberry[default]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: future in c:\\users\\utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages (from ffmpeg-python) (0.18.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python pyvirtualdisplay\n",
    "!apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOPiAupGmkxh"
   },
   "source": [
    "# Warm up: interacting with a reinforcement learning environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "6IZ0bVAlTjpZ",
    "outputId": "60cf10f4-8f13-4264-c281-1194beff4c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states =  13\n",
      "number of actions =  4\n",
      "transition probabilities from state 0 by taking action 1:  [0.  0.9 0.  0.  0.1 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
      "mean reward in state 0 for action 1 =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Not possible to save video, due to exception: [WinError 2] Le fichier spécifié est introuvable \n"
     ]
    }
   ],
   "source": [
    "from rlberry.envs import GridWorld\n",
    "\n",
    "# A GridWorld is an environment where an agent moves in a 2d grid and aims to reach the state which gives a reward.\n",
    "env = GridWorld(nrows=3, ncols=5, walls=((0,2),(1, 2)), success_probability=0.9)\n",
    "\n",
    "# Number of states and actions\n",
    "print(\"number of states = \", env.observation_space.n)\n",
    "print(\"number of actions = \", env.action_space.n)\n",
    "\n",
    "# Transitions probabilities, env.P[s, a, s'] = P(s'|s, a)\n",
    "print(\"transition probabilities from state 0 by taking action 1: \", env.P[0, 1, :])\n",
    "\n",
    "# Reward function: env.R[s, a] = r(s, a)\n",
    "print(\"mean reward in state 0 for action 1 = \", env.R[0, 1])\n",
    "\n",
    "# Following a random policy \n",
    "state = env.reset()     # initial state \n",
    "env.enable_rendering()  # save states for visualization\n",
    "for tt in range(100):   # interact for 100 time steps\n",
    "  action = env.action_space.sample()  # random action, a good RL agent must have a better strategy!\n",
    "  next_state, reward, is_terminal, info = env.step(action)\n",
    "  if is_terminal:\n",
    "    break\n",
    "  state = next_state\n",
    "\n",
    "# save video \n",
    "env.save_video('/videos/random_policy.mp4', framerate=10)\n",
    "# clear rendering data\n",
    "env.clear_render_buffer()\n",
    "env.disable_rendering()\n",
    "# see video\n",
    "#show_video(filename='./videos/random_policy.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snmFW5Bzqpwj"
   },
   "source": [
    "# Implementing Value Iteration\n",
    "\n",
    "1. Write a function ``bellman_operator`` that takes as input a function $Q$ and returns $T^* Q$.\n",
    "2. Write a function  ``value_iteration`` that returns a function $Q$ such that $||Q-T^* Q||_\\infty \\leq \\varepsilon$\n",
    "3. Evaluate the performance of the policy $\\pi(s) = \\arg\\max_a Q(s, a)$, where Q is returned by ``value_iteration``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RPIOmpjkq0YX"
   },
   "outputs": [],
   "source": [
    "def bellman_operator(Q, env, gamma=0.99):\n",
    "  S = env.observation_space.n\n",
    "  A = env.action_space.n \n",
    "  TQ = np.zeros((S, A))\n",
    "\n",
    "  for state in range(S):\n",
    "    for action in range(A):\n",
    "      sum=0\n",
    "      for s in range(S):\n",
    "        q=np.max(Q[s,:])\n",
    "        sum+=q*env.P[state,action,s]\n",
    "      TQ[state,action]=env.R[state,action]+gamma*sum\n",
    "  return TQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "S = env.observation_space.n\n",
    "A = env.action_space.n \n",
    "Q = np.zeros((S, A))\n",
    "tabError=[]\n",
    "for i in range(100):\n",
    "  TQ=bellman_operator(Q,env=env,gamma=0.9)\n",
    "  tabError.append(np.max(np.abs(TQ-Q)))\n",
    "  Q=TQ\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,100,100),tabError)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tEKAtA1LsYFx"
   },
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=0.99, epsilon=1e-6,Niter=10000):\n",
    "  S = env.observation_space.n\n",
    "  A = env.action_space.n \n",
    "  Q = np.zeros((S, A))\n",
    "  Q_prev = np.zeros((S, A))\n",
    "  prev_state=env.state\n",
    "  prev_action=0\n",
    "  TabError=[]\n",
    "  t=0\n",
    "  while t<Niter :\n",
    "    Q_prev=Q\n",
    "    Q=bellman_operator(Q,env,gamma)\n",
    "    error=np.max(np.abs(Q-Q_prev))\n",
    "    TabError.append(error)\n",
    "    if error<epsilon:\n",
    "      break\n",
    "  return Q,TabError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.8999999999999999, 0.81, 0.7290000000000001, 0.6561000000000003, 0.59049, 0.531441, 0.47829690000000014, 0.43046720999999977, 0.38742048900000015, 0.3486784401000005, 0.3138105960899997, 0.28242953648099967, 0.25418658283289997, 0.2287679245496097, 0.20589113209465015, 0.18530201888518505, 0.16677181699666477, 0.1500946352969983, 0.13508517176729917, 0.12157665459056943, 0.10941898913151249, 0.0984770902183616, 0.08862938119652597, 0.0797664430768723, 0.0717897987691849, 0.06461081889226605, 0.05814973700304016, 0.052334763302736675, 0.047101286972463186, 0.042391158275215446, 0.03815204244769532, 0.034336838202925435, 0.030903154382633247, 0.027812838944369034, 0.025031555049931598, 0.022528399544938793, 0.020275559590444914, 0.018248003631400778, 0.016423203268260522, 0.014780882941435536, 0.013302794647293226, 0.01197251518256337, 0.010775263664307033, 0.00969773729787704, 0.008727963568089692, 0.007855167211281433, 0.007069650490152846, 0.0063626854411378275, 0.005726416897024578, 0.0051537752073222975, 0.004638397686590245, 0.00417455791793131, 0.0037571021261388893, 0.0033813919135248227, 0.0030432527221728733, 0.0027389274499567406, 0.0024650347049597343, 0.0022185312344644714, 0.001996678111017225, 0.0017970102999163018, 0.0016173092699247604, 0.001455578342934416, 0.0013100205086420402, 0.0011790184577771257, 0.0010611166120000348, 0.0009550049508000313, 0.0008595044557200282, 0.0007735540101476701, 0.0006961986091340577, 0.0006265787482195861, 0.0005639208733967394, 0.000507528786059197, 0.0004567759074536326, 0.00041109831670826935, 0.0003699884850369983, 0.0003329896365338314, 0.0002996906728807147, 0.0002697216055924656, 0.00024274944503321905, 0.0002184745005306965, 0.00019662705047807094, 0.00017696434543079675, 0.00015926791088816117, 0.0001433411197995227, 0.0001290070078194816, 0.00011610630703806635, 0.00010449567633408208, 9.404610870156205e-05]\n"
     ]
    }
   ],
   "source": [
    "itermax=1000\n",
    "\n",
    "Q,tabError=value_iteration(env=env,gamma=0.9,epsilon=0.0001,Niter=itermax)\n",
    "plt.figure()\n",
    "#plt.plot(np.linspace(0,itermax,itermax),tabError)\n",
    "plt.show()\n",
    "print(tabError)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "rZ7k-rDLssSk",
    "outputId": "7731f953-093d-4c3b-e84f-1b356eb892c3"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m env\u001b[39m.\u001b[39menable_rendering()  \n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m tt \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):   \n\u001b[1;32m----> 7\u001b[0m   action \u001b[39m=\u001b[39m Q_vi[state, :]\u001b[39m.\u001b[39margmax()\n\u001b[0;32m      8\u001b[0m   next_state, reward, is_terminal, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m      9\u001b[0m   \u001b[39mif\u001b[39;00m is_terminal:\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "Q_vi = value_iteration(env)\n",
    "\n",
    "# Following value iteration policy \n",
    "state = env.reset()     \n",
    "env.enable_rendering()  \n",
    "for tt in range(100):   \n",
    "  action = Q_vi[state, :].argmax()\n",
    "  next_state, reward, is_terminal, info = env.step(action)\n",
    "  if is_terminal:\n",
    "    break\n",
    "  state = next_state\n",
    "\n",
    "# save video (run last cell to visualize it!)\n",
    "env.save_video('./videos/value_iteration_policy.mp4', framerate=10)\n",
    "# clear rendering data\n",
    "env.clear_render_buffer()\n",
    "env.disable_rendering()\n",
    "# see video\n",
    "show_video(filename='./videos/value_iteration_policy.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Uw6LVyVulOX"
   },
   "source": [
    "# Implementing Q-Learning\n",
    "\n",
    "Implement a function ``q_learning`` that takes as input an environment, runs Q learning for $T$ time steps and returns $Q_T$. \n",
    "\n",
    "Test different learning rates:\n",
    "  * $\\alpha_t(s, a) = \\frac{1}{\\text{number of visits to} (s, a)}$\n",
    "  * $\\alpha_t(s, a) =$ constant in $]0, 1[$\n",
    "  * others?\n",
    "\n",
    "Test different initializations of the Q function and try different values of $\\varepsilon$ in the $\\varepsilon$-greedy exploration!\n",
    "\n",
    "It might be very useful to plot the difference between the Q-learning approximation and the output of value iteration above, as a function of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "OrhUOlrfv6xp"
   },
   "outputs": [],
   "source": [
    "def q_learning(env, gamma=0.99, T=5000, Q_vi=None):\n",
    "  \"\"\"\n",
    "  Q_vi is the output of value iteration.\n",
    "  \"\"\"\n",
    "  epsilon=0.5\n",
    "  S = env.observation_space.n\n",
    "  A = env.action_space.n \n",
    "  error = np.zeros(T)\n",
    "  Q = np.zeros((S, A))  # can we improve this initialization? \n",
    "  #Choix du alpha : \n",
    "  alpha=0.5\n",
    "\n",
    "  state = env.reset()\n",
    "    # to complete...\n",
    "  for tt in range(T):\n",
    "    # choose action a_t\n",
    "    rand=rd.uniform(0,1)\n",
    "    if rand<epsilon:\n",
    "      action = rd.randint(0,A-1)\n",
    "    else:\n",
    "      action = np.max(Q[state,:])\n",
    "    # take action, observe next state and reward \n",
    "    nex_state,reward,isTerminal,info = env.step(action)\n",
    "    # compute delta_t\n",
    "    delta_t=reward+gamma*(np.max(Q[next_state,:]))-Q[state,action]\n",
    "    # update Q\n",
    "    Q[state,action]=Q[state,action]+alpha*delta_t\n",
    "    Q_vi=value_iteration(env=env,gamma=0.99,epsilon=0.0000001)\n",
    "    \n",
    "    error[tt] = np.abs(Q-Q_vi).max()\n",
    "  \n",
    "  plt.plot(error)\n",
    "  plt.xlabel('iteration')\n",
    "  plt.title('Q-Learning error')\n",
    "  plt.show()\n",
    "  \n",
    "  return Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "fOetdWM4xhLt",
    "outputId": "f755ca3f-86f1-4c48-ffe7-fa88d1dc68b3"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid action!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Q_ql \u001b[39m=\u001b[39m q_learning(env, Q_vi\u001b[39m=\u001b[39;49mQ_vi)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Following Q-Learning policy \u001b[39;00m\n\u001b[0;32m      4\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()     \n",
      "Cell \u001b[1;32mIn[42], line 23\u001b[0m, in \u001b[0;36mq_learning\u001b[1;34m(env, gamma, T, Q_vi)\u001b[0m\n\u001b[0;32m     21\u001b[0m   action\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmax(Q[state,:])\n\u001b[0;32m     22\u001b[0m \u001b[39m# take action, observe next state and reward \u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m nex_state,reward,isTerminal,info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     24\u001b[0m \u001b[39m# compute delta_t\u001b[39;00m\n\u001b[0;32m     25\u001b[0m delta_t\u001b[39m=\u001b[39mreward\u001b[39m+\u001b[39mgamma\u001b[39m*\u001b[39m(np\u001b[39m.\u001b[39mmax(Q[next_state,:]))\u001b[39m-\u001b[39mQ[state,action]\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\rltutorials\\lib\\site-packages\\rlberry\\envs\\finite\\gridworld.py:344\u001b[0m, in \u001b[0;36mGridWorld.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m--> 344\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(action), \u001b[39m\"\u001b[39m\u001b[39mInvalid action!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m     \u001b[39m# save state for rendering\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_render_enabled():\n",
      "\u001b[1;31mAssertionError\u001b[0m: Invalid action!"
     ]
    }
   ],
   "source": [
    "Q_ql = q_learning(env, Q_vi=Q_vi)\n",
    "\n",
    "# Following Q-Learning policy \n",
    "state = env.reset()     \n",
    "env.enable_rendering()  \n",
    "for tt in range(100):   \n",
    "  action = Q_ql[state, :].argmax()\n",
    "  next_state, reward, is_terminal, info = env.step(action)\n",
    "  if is_terminal:\n",
    "    break\n",
    "  state = next_state\n",
    "\n",
    "# save video (run last cell to visualize it!)\n",
    "env.save_video('./videos/q_learning_policy.mp4', framerate=10)\n",
    "# clear rendering data\n",
    "env.clear_render_buffer()\n",
    "env.disable_rendering()\n",
    "# see video\n",
    "show_video(filename='./videos/q_learning_policy.mp4')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+8H1rbTADo1Hh3m1E+mXQ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Tutorial - Value Iteration and Q-Learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 ('rltutorials')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "22fb3692bee311354396abce5de73f147db26a6651d0fabb33560b91bb1fb1cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
